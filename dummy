import pandas as pd
import numpy as np
import calendar
from pandas.tseries.holiday import USFederalHolidayCalendar

# -------------- LOAD DATA -----------------
# df must have at least a 'timestamp' column in datetime format
# and a 'cluster' column indicating KMeans cluster assignment
#
# Example:
# df = pd.read_csv("your_file.csv")
# df['timestamp'] = pd.to_datetime(df['timestamp'])

# -------------- ENRICH DATA -----------------
df['timestamp'] = pd.to_datetime(df['timestamp'])
df['date'] = df['timestamp'].dt.date
df['day_of_week'] = df['timestamp'].dt.dayofweek
df['day'] = df['timestamp'].dt.day
df['month'] = df['timestamp'].dt.month
df['year'] = df['timestamp'].dt.year

# -------------- PATTERN CHECKING UTILS -----------------
def pattern_with_tolerance(fn, threshold=0.9):
    def wrapper(cluster_df):
        mask = fn(cluster_df)
        return mask.sum() / len(cluster_df) >= threshold
    return wrapper

# 1. Same day of week
def same_weekday_mask(df):
    mode_day = df['day_of_week'].mode()[0]
    return df['day_of_week'] == mode_day

# 2. Nieme occurrence of weekday in month
def get_weekday_occurrence_in_month(row):
    weekday = row['day_of_week']
    month_days = pd.date_range(start=f"{row['year']}-{row['month']:02d}-01", 
                               end=f"{row['year']}-{row['month']:02d}-{calendar.monthrange(row['year'], row['month'])[1]}")
    same_weekdays = [d for d in month_days if d.weekday() == weekday]
    return sum(d.day <= row['day'] for d in same_weekdays)

df['weekday_occurrence'] = df.apply(get_weekday_occurrence_in_month, axis=1)

def nth_weekday_occurrence_mask(df):
    mode = df.groupby(['day_of_week'])['weekday_occurrence'].agg(lambda x: x.mode().iloc[0])
    return df.apply(lambda row: row['weekday_occurrence'] == mode.get(row['day_of_week'], -1), axis=1)

# 3. Every calendar day (tolerant)
def calendar_day_mask(df):
    all_days = set(range(1, df['timestamp'].dt.days_in_month.max() + 1))
    present_days = set(df['day'].unique())
    missing = all_days - present_days
    return df['day'].isin(all_days - missing)

# 4. Every business day
def business_day_mask(df):
    bdays = pd.bdate_range(start=df['timestamp'].min().date(), end=df['timestamp'].max().date())
    valid_dates = set(bdays.date)
    return df['date'].isin(valid_dates)

# 5. Nieme business day of month
def get_business_day_rank(row):
    year, month = row['year'], row['month']
    bdays = pd.bdate_range(start=f"{year}-{month:02d}-01", 
                           end=f"{year}-{month:02d}-{calendar.monthrange(year, month)[1]}")
    try:
        return np.where(bdays.date == row['date'])[0][0] + 1
    except:
        return np.nan

df['bizday_rank'] = df.apply(get_business_day_rank, axis=1)

def nth_business_day_mask(df):
    mode = df['bizday_rank'].mode()[0]
    return df['bizday_rank'] == mode

# 6. Last business day of month
def is_last_business_day_of_month(date):
    year, month = date.year, date.month
    bdays = pd.bdate_range(start=f"{year}-{month:02d}-01", 
                           end=f"{year}-{month:02d}-{calendar.monthrange(year, month)[1]}")
    return date == bdays[-1].date()

df['is_last_bizday'] = df['date'].apply(is_last_business_day_of_month)

def last_bizday_mask(df):
    return df['is_last_bizday']

# 7. Last weekday occurrence of the month
def is_last_weekday_occurrence(date):
    weekday = date.weekday()
    last_day = calendar.monthrange(date.year, date.month)[1]
    last_date = pd.Timestamp(f"{date.year}-{date.month}-{last_day}")
    while last_date.weekday() != weekday:
        last_date -= pd.Timedelta(days=1)
    return date == last_date.date()

df['is_last_weekday_of_month'] = df['date'].apply(is_last_weekday_occurrence)

def last_weekday_of_month_mask(df):
    return df['is_last_weekday_of_month']

# -------------- ANALYZE EACH CLUSTER -----------------
tolerance_threshold = 0.9  # allow 10% noise
results = []

for cluster_id, group in df.groupby('cluster'):
    result = {
        'cluster': cluster_id,
        'same_weekday': pattern_with_tolerance(same_weekday_mask, tolerance_threshold)(group),
        'nth_weekday_occurrence': pattern_with_tolerance(nth_weekday_occurrence_mask, tolerance_threshold)(group),
        'every_calendar_day': pattern_with_tolerance(calendar_day_mask, tolerance_threshold)(group),
        'every_business_day': pattern_with_tolerance(business_day_mask, tolerance_threshold)(group),
        'nth_business_day': pattern_with_tolerance(nth_business_day_mask, tolerance_threshold)(group),
        'last_business_day': pattern_with_tolerance(last_bizday_mask, tolerance_threshold)(group),
        'last_weekday_in_month': pattern_with_tolerance(last_weekday_of_month_mask, tolerance_threshold)(group)
    }
    results.append(result)

pattern_df = pd.DataFrame(results)
print(pattern_df)


# -------------- EXTRA ANALYSIS FOR CLUSTER 12 -----------------
cluster_id = 12
cluster_df = df[df['cluster'] == cluster_id].copy()

# Step 1: Identify dominant weekday
dominant_weekday = cluster_df['day_of_week'].mode()[0]  # 0 = Monday, ..., 6 = Sunday
weekday_name = calendar.day_name[dominant_weekday]
print(f"\nMost common weekday in cluster {cluster_id}: {weekday_name} (#{dominant_weekday})")

# Step 2: Count how many files on that day
count_on_dominant_day = (cluster_df['day_of_week'] == dominant_weekday).sum()
total = len(cluster_df)
ratio = count_on_dominant_day / total
print(f"{count_on_dominant_day} out of {total} files ({ratio:.2%}) arrive on {weekday_name}")

# Step 3: Weekly recurrence check
cluster_df['week'] = cluster_df['timestamp'].dt.isocalendar().week
cluster_df['year'] = cluster_df['timestamp'].dt.isocalendar().year

weekday_df = cluster_df[cluster_df['day_of_week'] == dominant_weekday]
weeks_with_arrivals = set(zip(weekday_df['year'], weekday_df['week']))
all_weeks = set(zip(cluster_df['year'], cluster_df['week']))
coverage_ratio = len(weeks_with_arrivals) / len(all_weeks)

print(f"Files arrived on {weekday_name} in {len(weeks_with_arrivals)} of {len(all_weeks)} weeks ({coverage_ratio:.2%})")
if coverage_ratio >= 0.8:
    print(f"âœ… Pattern: Weekly arrival on {weekday_name} with tolerance 0.8")
else:
    print(f"âŒ Not enough weekly consistency on {weekday_name} (need â‰¥ 80%)")

# Optional: Plot arrivals per week
weekday_df['year_week'] = weekday_df['timestamp'].dt.strftime('%Y-W%U')
weekday_counts = weekday_df['year_week'].value_counts().sort_index()

plt.figure(figsize=(12, 4))
weekday_counts.plot(kind='bar')
plt.title(f'Arrivals on {weekday_name} per Week - Cluster {cluster_id}')
plt.xlabel('Year-Week')
plt.ylabel('Number of Files')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()


# ------------------------ CONFIG ------------------------
CLUSTER_ID = 5
TOLERANCE = 0.8  # 80% consistency required

# ------------------------ INPUT -------------------------
# Ensure your DataFrame is loaded and parsed properly:
# df = pd.read_csv("your_file.csv")
# df['timestamp'] = pd.to_datetime(df['timestamp'])

# For demo purposes, you must already have:
# df['cluster'] and df['timestamp'] columns

# ------------------------ FILTER CLUSTER -------------------------
df['timestamp'] = pd.to_datetime(df['timestamp'])
df['year'] = df['timestamp'].dt.year
df['month'] = df['timestamp'].dt.month
df['day'] = df['timestamp'].dt.day
df['day_of_week'] = df['timestamp'].dt.dayofweek  # Monday=0, Sunday=6
df['date'] = df['timestamp'].dt.date

cluster_df = df[df['cluster'] == CLUSTER_ID].copy()

# ------------------------ COMPUTE N-th OCCURRENCE -------------------------
def get_weekday_occurrence(row):
    year = row['year']
    month = row['month']
    weekday = row['day_of_week']
    days = pd.date_range(f"{year}-{month:02d}-01", f"{year}-{month:02d}-{calendar.monthrange(year, month)[1]}")
    same_weekdays = [d.day for d in days if d.weekday() == weekday]
    return same_weekdays.index(row['day']) + 1 if row['day'] in same_weekdays else np.nan

cluster_df['weekday_occurrence'] = cluster_df.apply(get_weekday_occurrence, axis=1)

# ------------------------ FIND DOMINANT PATTERN -------------------------
# Most frequent (weekday, occurrence) pair
dominant_combo = (
    cluster_df.groupby(['day_of_week', 'weekday_occurrence'])
    .size()
    .idxmax()
)
dominant_weekday, dominant_occurrence = dominant_combo
weekday_name = calendar.day_name[dominant_weekday]

print(f"Most common N-th weekday pattern in Cluster {CLUSTER_ID}:")
print(f"ðŸ—“ï¸  {dominant_occurrence}-th {weekday_name} of each month")

# ------------------------ TOLERANCE CHECK -------------------------
# Check how many rows match this dominant pattern
mask = (
    (cluster_df['day_of_week'] == dominant_weekday) &
    (cluster_df['weekday_occurrence'] == dominant_occurrence)
)
match_count = mask.sum()
total_count = len(cluster_df)
match_ratio = match_count / total_count

print(f"\nâœ… {match_count} of {total_count} files ({match_ratio:.2%}) match this pattern")

if match_ratio >= TOLERANCE:
    print(f"âœ”ï¸ Pattern detected with tolerance â‰¥ {TOLERANCE:.0%}")
else:
    print(f"âŒ Pattern does not meet tolerance threshold of {TOLERANCE:.0%}")

# ------------------------ OPTIONAL VISUALIZATION -------------------------
plot_df = cluster_df.copy()
plot_df['label'] = np.where(mask, f"{dominant_occurrence}-th {weekday_name}", "Other")

plt.figure(figsize=(10, 4))
plot_df['label'].value_counts().plot(kind='bar', color=['green', 'red'])
plt.title(f"Cluster {CLUSTER_ID} â€“ Match to N-th {weekday_name} Pattern")
plt.ylabel("Number of Files")
plt.xlabel("Match Type")
plt.tight_layout()
plt.show()


cluster_id = 12
cluster_df = df[df['cluster'] == cluster_id].copy()

# Step 1: Analyze all weekdays in the cluster
weekday_counts = cluster_df['day_of_week'].value_counts().sort_index()
print(f"\nWeekday counts in cluster {cluster_id}:")
for day_idx, count in weekday_counts.items():
    print(f"{calendar.day_name[day_idx]}: {count} files")

# Step 2: Identify top combinations (e.g., Tuesday and Wednesday)
dominant_days = weekday_counts[weekday_counts >= weekday_counts.max() * 0.8].index.tolist()
dominant_names = [calendar.day_name[d] for d in dominant_days]
print(f"\nDominant weekdays (>= 80% of max): {dominant_names}")

# Step 3: Check weekly coverage for these days
cluster_df['week'] = cluster_df['timestamp'].dt.isocalendar().week
cluster_df['year'] = cluster_df['timestamp'].dt.isocalendar().year
cluster_df['year_week'] = cluster_df['timestamp'].dt.strftime('%Y-W%U')

def coverage_for_day(day):
    day_df = cluster_df[cluster_df['day_of_week'] == day]
    weeks_with_arrivals = set(zip(day_df['year'], day_df['week']))
    all_weeks = set(zip(cluster_df['year'], cluster_df['week']))
    return day, len(weeks_with_arrivals), len(all_weeks), len(weeks_with_arrivals) / len(all_weeks)

print(f"\nWeekly coverage:")
for d in dominant_days:
    day, hits, total_weeks, ratio = coverage_for_day(d)
    print(f"{calendar.day_name[day]}: {hits}/{total_weeks} weeks ({ratio:.2%})")

# Step 4: Plot weekly file count for each dominant day
plt.figure(figsize=(12, 6))
for d in dominant_days:
    day_df = cluster_df[cluster_df['day_of_week'] == d].copy()
    weekly_counts = day_df['year_week'].value_counts().sort_index()
    plt.plot(weekly_counts.index, weekly_counts.values, label=calendar.day_name[d])

plt.title(f"Weekly Arrivals by Dominant Weekdays - Cluster {cluster_id}")
plt.xlabel("Year-Week")
plt.ylabel("Number of Files")
plt.xticks(rotation=45)
plt.legend()
plt.tight_layout()
plt.show()

# ------------------ ANALYZE EACH FILENAME_CLEANED ------------------
filename_results = []

for fname, group in df.groupby('filename_cleaned'):
    result = {
        'filename_cleaned': fname,
        'file_count': len(group),
        'same_weekday': pattern_with_tolerance(same_weekday_mask, tolerance_threshold)(group),
        'nth_weekday_occurrence': pattern_with_tolerance(nth_weekday_occurrence_mask, tolerance_threshold)(group),
        'every_calendar_day': pattern_with_tolerance(calendar_day_mask, tolerance_threshold)(group),
        'every_business_day': pattern_with_tolerance(business_day_mask, tolerance_threshold)(group),
        'nth_business_day': pattern_with_tolerance(nth_business_day_mask, tolerance_threshold)(group),
        'last_business_day': pattern_with_tolerance(last_bizday_mask, tolerance_threshold)(group),
        'last_weekday_in_month': pattern_with_tolerance(last_weekday_of_month_mask, tolerance_threshold)(group)
    }
    filename_results.append(result)

filename_pattern_df = pd.DataFrame(filename_results)

# Display patterns
print("\n========== Reception Patterns by filename_cleaned ==========")
print(filename_pattern_df.sort_values("file_count", ascending=False))



# Step 5: Analyze file_name_cleaned patterns on dominant weekday
print(f"\nðŸ—‚ï¸ File recurrence on {weekday_name} in cluster {cluster_id}:")

# Group by file and count in how many unique weeks it arrived on the dominant weekday
file_week_counts = (
    weekday_df.groupby('file_name_cleaned')
    .apply(lambda g: len(set(zip(g['year'], g['week']))))
    .reset_index(name='weeks_present')
)

# Total number of weeks in the cluster
total_weeks_in_cluster = len(all_weeks)

# Add recurrence ratio column
file_week_counts['recurrence_ratio'] = file_week_counts['weeks_present'] / total_weeks_in_cluster

# Show only files with recurrence >= 0.8 (optional)
recurrent_files = file_week_counts[file_week_counts['recurrence_ratio'] >= 0.8]

print(file_week_counts.sort_values(by='recurrence_ratio', ascending=False))

print(f"\nâœ… Files with weekly recurrence on {weekday_name} (â‰¥ 80% of weeks):")
print(recurrent_files)

# Optional bar plot of file recurrence
plt.figure(figsize=(12, 4))
plt.bar(file_week_counts['file_name_cleaned'], file_week_counts['recurrence_ratio'])
plt.axhline(0.8, color='red', linestyle='--', label='80% threshold')
plt.title(f'Weekly Recurrence of Files on {weekday_name} - Cluster {cluster_id}')
plt.ylabel('Recurrence Ratio')
plt.xlabel('File Name')
plt.xticks(rotation=90)
plt.legend()
plt.tight_layout()
plt.show()

